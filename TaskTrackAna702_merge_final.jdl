# Generated merging jdl                     
# $1 = full alien path to output directory to be merged                     
# $2 = merging stage                     
# xml made via: find <OutputDir> *Stage<n-1>/*root_archive.zip
Jobtag = {
   "comment:Automatically generated analysis JDL_FinalMerging"
};
# Collection of files to be merged for current stage

# Output directory
OutputDir = "$1";
# List of requested packages
Packages = {
   "VO_ALICE@AliPhysics::vAN-20171012-1",
   "VO_ALICE@APISCONFIG::V1.1x"
};
# List of input files to be uploaded to workers
InputFile = {
   "LF:/alice/cern.ch/user/a/aberdnik/Ali_AS_analysis_TRD_digits/sub702//TaskTrackAna702_merge.C",
   "LF:/alice/cern.ch/user/a/aberdnik/Ali_AS_analysis_TRD_digits/sub702//TaskTrackAna702.root",
   "LF:/alice/cern.ch/user/a/aberdnik/Ali_AS_analysis_TRD_digits/sub702//Ali_AS_Event.h",
   "LF:/alice/cern.ch/user/a/aberdnik/Ali_AS_analysis_TRD_digits/sub702//Ali_AS_EventLinkDef.h",
   "LF:/alice/cern.ch/user/a/aberdnik/Ali_AS_analysis_TRD_digits/sub702//Ali_AS_analysis_TRD_digits.h",
   "LF:/alice/cern.ch/user/a/aberdnik/Ali_AS_analysis_TRD_digits/sub702//Ali_AS_analysis_TRD_digits.cxx",
   "LF:$1/Stage_$2.xml"
};
# This is the startup script
Executable = "/alice/cern.ch/user/a/aberdnik/Ali_AS_analysis_TRD_digits/sub702//TaskTrackAna702_merge.sh";
# We split per SE for merging in stages
# Time after which the job is killed (333 min.)
TTL = "19999";
# Maximum number of input files to be merged in one go
# Format of input data
# Collection name to be processed on each worker node
# List of output files and archives
Output = {
   "log_archive.zip:std*@disk=1",
   "root_archive.zip:AnalysisResults*.root,*.stat@disk=2"
};
Arguments = "Stage_$2.xml $2";
# AliEn price for this job
Price = "1";
# Validation script to be run for each subjob
Validationcommand = "/alice/cern.ch/user/a/aberdnik/Ali_AS_analysis_TRD_digits/sub702//TaskTrackAna702_validation_merge.sh";
User = "aberdnik";
Workdirectorysize = {"5000MB"};
